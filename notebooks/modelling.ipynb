{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b05344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    " \n",
    "sys.path.insert(0, '/Users/dominicbates/Documents/Github/fpl-model/')\n",
    "from fpl_model.load_data import load_data\n",
    "from fpl_model.process_data import do_all_processing_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f76d259",
   "metadata": {},
   "source": [
    "### Load and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8333937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading data...\n",
      "Loading data for years: ['2022-23', '2021-22', '2020-21', '2019-20', '2018-19', '2017-18', '2016-17']\n",
      "... Processing year: 2022-23\n",
      "... Processing year: 2021-22\n",
      "... Processing year: 2020-21\n",
      "... Processing year: 2019-20\n",
      "... Processing year: 2018-19\n",
      "... Processing year: 2017-18\n",
      "... Processing year: 2016-17\n",
      "\n",
      "Dropping Nulls\n",
      "... Size: 166653\n",
      "... New Size: 165873\n",
      "... 780 rows dropped\n",
      "\n",
      "Data loaded!\n",
      "\n",
      "Processing opponent feature (goals conceded over last N weeks)...\n",
      "... 0 / 165873 rows complete\n",
      "... 10000 / 165873 rows complete\n",
      "... 20000 / 165873 rows complete\n",
      "... 30000 / 165873 rows complete\n",
      "... 40000 / 165873 rows complete\n",
      "... 50000 / 165873 rows complete\n",
      "... 60000 / 165873 rows complete\n",
      "... 70000 / 165873 rows complete\n",
      "... 80000 / 165873 rows complete\n",
      "... 90000 / 165873 rows complete\n",
      "... 100000 / 165873 rows complete\n",
      "... 110000 / 165873 rows complete\n",
      "... 120000 / 165873 rows complete\n",
      "... 130000 / 165873 rows complete\n",
      "... 140000 / 165873 rows complete\n",
      "... 150000 / 165873 rows complete\n",
      "... 160000 / 165873 rows complete\n",
      "\n",
      "Feature processed!\n",
      "\n",
      "Processing features...\n",
      "Processing dataframe binned features\n",
      "... 0 / 165873 rows complete\n",
      "... 10000 / 165873 rows complete\n",
      "... 20000 / 165873 rows complete\n",
      "... 30000 / 165873 rows complete\n",
      "... 40000 / 165873 rows complete\n",
      "... 50000 / 165873 rows complete\n",
      "... 60000 / 165873 rows complete\n",
      "... 70000 / 165873 rows complete\n",
      "... 80000 / 165873 rows complete\n",
      "... 90000 / 165873 rows complete\n"
     ]
    }
   ],
   "source": [
    "df = load_data()\n",
    "df = do_all_processing_steps(df, history_size = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a3c69f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343d0790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_from_groups(feature_groups):\n",
    "    '''\n",
    "    Selects all features ('f|...|...') in dataframe containing any of these keys \n",
    "    '''\n",
    "    return [col for col in list(df) if np.sum([f in col for f in feature_groups])>0 and ('f|' in col)]\n",
    "\n",
    "\n",
    "feature_groups = ['total_points', \n",
    "                  'minutes', \n",
    "                  'was_home', \n",
    "                  'opponent_gc_history', \n",
    "                  'opponent_gc_history_available',\n",
    "                  'current_season',\n",
    "                  'player_exists',\n",
    "                  'current']\n",
    "\n",
    "\n",
    "features = get_features_from_groups(feature_groups)\n",
    "target = 'total_points'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ba9948",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7793da3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "default_configs = {'XGBoost':{'max_depth':6,\n",
    "                              'eta':0.3,\n",
    "                              'n_estimators':10,\n",
    "#                               'min_child_weight':1,\n",
    "                              'subsample':1,\n",
    "#                               'lambda':1,\n",
    "                              'num_parallel_tree':1\n",
    "                              },\n",
    "                   'LinearRegression':None,\n",
    "                    }\n",
    "\n",
    "\n",
    "\n",
    "class Classifier:\n",
    "    def __init__(self, \n",
    "                 features,\n",
    "#                  target,\n",
    "                 classifier='XGBoost',\n",
    "                 config=None):\n",
    "        \n",
    "        '''\n",
    "        Model object\n",
    "        '''\n",
    "        \n",
    "        # Check input first\n",
    "        classifiers_list = ['LinearRegression',\n",
    "                            'XGBoost']\n",
    "        if classifier not in classifiers_list:\n",
    "            raise ValueError('Classifier \"'+str(classifier)+'\" not in list. Try one of:',classifiers_list)\n",
    "        \n",
    "        # Set config params\n",
    "        if config is None:\n",
    "            self.config = default_configs[classifier]\n",
    "        else:\n",
    "            self.config = config\n",
    "\n",
    "        # Get relevant model\n",
    "        self.classifier = classifier\n",
    "        if classifier == 'LogisticRegression':\n",
    "            self.model = LogisticRegression(C=2, penalty = 'l2', max_iter=1000, random_state=0, fit_intercept=True)\n",
    "        elif classifier == 'XGBoost':\n",
    "            self.model = XGBRegressor(max_depth=self.config['max_depth'],\n",
    "                                      eta=self.config['eta'],\n",
    "                                      n_estimators = self.config['n_estimators'],\n",
    "#                                        min_child_weight=self.config['min_child_weight'],\n",
    "                                      subsample=self.config['subsample'],\n",
    "#                                        reg_lambda=self.config['lambda'],\n",
    "                                      num_parallel_tree=self.config['num_parallel_tree'])\n",
    "        self.model_fit = False\n",
    "\n",
    "        # Store features in model\n",
    "        self.features = features\n",
    "#         self.taget = target\n",
    "            \n",
    "\n",
    "            \n",
    "    def fit(self, vals_X, vals_y, weights = None):\n",
    "        self.model.fit(vals_X, vals_y, sample_weight= weights)\n",
    "        pred_y = self.apply(vals_X)\n",
    "        self.print_performance(vals_y, pred_y, sample_weight = weights, print_output=True)\n",
    "        \n",
    "        \n",
    "    def apply(self, vals_X):\n",
    "        if self.model_fit is None:\n",
    "            raise ValueError('Model not trained yet. Run fit() first')\n",
    "        else:\n",
    "            return self.model.predict(vals_X)\n",
    "\n",
    "#     def apply_proba(self, vals_X):\n",
    "#         if self.model_fit is None:\n",
    "#             raise ValueError('Model not trained yet. Run fit() first')\n",
    "#         else:\n",
    "#             return self.model.predict_proba(vals_X)\n",
    "    \n",
    "    \n",
    "    def print_performance(self, vals_y, pred_y, weights = None, print_output=True):\n",
    "        mae_val = mean_absolute_error(vals_y, pred_y, sample_weight = weights)\n",
    "        mse_val = mean_squared_error(vals_y, pred_y, sample_weight = weights)\n",
    "\n",
    "        if print==True:\n",
    "            print('\\nMean Absolute Error:')\n",
    "            print(mae_val)\n",
    "            \n",
    "            print('\\nMean Squared Error:')\n",
    "            print(mse_val)\n",
    "        else:\n",
    "            return mae_val, mse_val\n",
    "        \n",
    "    def save_model(self, fpath):\n",
    "        print('Saving model to:',fpath)\n",
    "        with open(fpath, 'wb') as handle:\n",
    "            pickle.dump(self, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        print('Model saved!')\n",
    "\n",
    "    # def print_top_words(self, vectorizer, n = 100):\n",
    "\n",
    "    #     for c in range(0,len(self.model.classes_)):\n",
    "    #         top_ind = np.argsort(self.model.coef_[c])[-1*n:][::-1]\n",
    "    #         top_vals = ([self.model.coef_[c][i] for i in top_ind])\n",
    "\n",
    "    #         inverse_vocabulary = dict((v,k) for k,v in vectorizer.vocabulary_.items())\n",
    "    #         print('\\nTop words for class:',self.model.classes_[c])\n",
    "    #         words = [inverse_vocabulary[n]+', ' for n in top_ind]\n",
    "    #         print(''.join(words)[:-2])\n",
    "    #         print('')\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "def load_model(fpath):\n",
    "    print('Loading model from:',fpath)\n",
    "    with open(fpath, 'rb') as handle:\n",
    "        model = pickle.load(handle)\n",
    "        print('Model loaded!')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352b44bb",
   "metadata": {},
   "source": [
    "### Test fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e58c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier(features, classifier='XGBoost')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8560e8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_train = df['season'] != '2022-23'\n",
    "m_test = df['season'] == '2022-23'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553e2531",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(df[features][m_train], df[target][m_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606b66ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['p|total_points'] = model.apply(df[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be19221",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['name_cleaned'] == 'erling haaland']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2917e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8da4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
